{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as psy\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from config import configr\n",
    "from urllib.parse import quote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to the PostgreSQL databse...\n",
      "PostfreSQL database version: \n",
      "('PostgreSQL 16.4, compiled by Visual C++ build 1940, 64-bit',)\n",
      "Database connection terminated.\n"
     ]
    }
   ],
   "source": [
    "def connect():\n",
    "    connection = None\n",
    "    try: \n",
    "        params = configr()\n",
    "        print('Connection to the PostgreSQL databse...')\n",
    "        connection = psy.connect(**params)\n",
    "\n",
    "        # create a cursor\n",
    "        cursor = connection.cursor()\n",
    "        print('PostfreSQL database version: ')\n",
    "        cursor.execute(\"Select version()\")\n",
    "        db_version = cursor.fetchone()\n",
    "        print(db_version)\n",
    "        cursor.close()\n",
    "    except(Exception, psy.DatabaseError) as err:\n",
    "        print(err)\n",
    "    finally:\n",
    "        if connection is not None:\n",
    "            connection.close()\n",
    "            print('Database connection terminated.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Books data and insert records into Books Database\n",
    "\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "params = configr()\n",
    "conn = psy.connect(**params)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Extract Date from Date String\n",
    "def extract_year(date_str):\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', date_str)\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    return None\n",
    "\n",
    "def fetch_books_by_subject(subject, batch_size=100, max_books=100):\n",
    "    books_data = []\n",
    "    page = 0\n",
    "\n",
    "    while len(books_data) < max_books:\n",
    "        # Fetch books from Open Library API\n",
    "        url = f\"https://openlibrary.org/subjects/{subject}.json?limit={batch_size}&offset={page * batch_size}\"\n",
    "        print(f\"Requesting data from URL: {url}\")\n",
    "\n",
    "        response = requests.get(url)\n",
    "        print(f\"Response status code: {response.status_code}\")\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(\"Error fetching data from the API\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        if 'works' not in data:\n",
    "            print(\"No 'works' key in the response data. Check the subject or API documentation.\")\n",
    "            break\n",
    "\n",
    "        for book_info in data.get('works', []):\n",
    "            title = book_info.get(\"title\", \"\")[:255]  # Truncate to 255 characters\n",
    "            author = ', '.join([author['name'] for author in book_info.get(\"authors\", [])])[:255]  # Truncate to 255 characters\n",
    "            genre = subject[:100]  # Assuming genre column has enough length\n",
    "            year_published_str = book_info.get(\"first_publish_year\", \"\")\n",
    "            year_published = extract_year(str(year_published_str)) if year_published_str else None\n",
    "\n",
    "            # Fetch description from Google Books API\n",
    "            description = fetch_book_description_from_google_books(title)\n",
    "\n",
    "            book = {\n",
    "                \"title\": title,\n",
    "                \"author\": author,\n",
    "                \"genre\": genre,\n",
    "                \"year_published\": year_published,\n",
    "                \"summary\": description\n",
    "            }\n",
    "            books_data.append(book)\n",
    "\n",
    "            if len(books_data) >= max_books:\n",
    "                break\n",
    "\n",
    "        if len(data.get('works', [])) < batch_size:\n",
    "            print(\"No more books to fetch from the API.\")\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    print(f\"Fetched {len(books_data)} books for subject: {subject}\")\n",
    "    return books_data\n",
    "\n",
    "def fetch_book_description_from_google_books(title):\n",
    "    query = quote_plus(title)  # Encode the title to handle spaces and special characters\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes?q={query}&key=<yourKey>\"\n",
    "    print(f\"Requesting data from URL: {url}\")\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching data from Google Books API\")\n",
    "        return \"No description available.\"\n",
    "\n",
    "    data = response.json()\n",
    "    items = data.get('items', [])\n",
    "\n",
    "    if items:\n",
    "        book_info = items[0].get('volumeInfo', {})\n",
    "        return book_info.get('description', 'No description available.')\n",
    "    \n",
    "    return \"No description available.\"\n",
    "\n",
    "def insert_books(books):\n",
    "    if not books:\n",
    "        print(\"No books to insert.\")\n",
    "        return\n",
    "\n",
    "    # Delete all existing records from the table\n",
    "    cursor.execute(\"DELETE FROM books\")\n",
    "    conn.commit()\n",
    "    print(\"Deleted all existing records from the table.\")\n",
    "\n",
    "    book_records = [\n",
    "        (\n",
    "            book['title'], \n",
    "            book['author'], \n",
    "            book['genre'], \n",
    "            book['year_published'], \n",
    "            book['summary']\n",
    "        ) for book in books\n",
    "    ]\n",
    "    \n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT INTO books (title, author, genre, year_published, summary)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\", book_records)\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"Inserted {len(book_records)} books into the database.\")\n",
    "\n",
    "def main():\n",
    "    genres = [\n",
    "        \"fiction\", \"mystery\", \"science\", \"history\", \"biography\", \"fantasy\", \n",
    "        \"romance\", \"non-fiction\", \"horror\", \"adventure\",\n",
    "        \"science-fiction\", \"thriller\", \"poetry\", \"philosophy\", \"travel\", \n",
    "        \"humor\", \"art\", \"religion\", \"spirituality\"\n",
    "    ]\n",
    "\n",
    "    all_books = []\n",
    "    for genre in genres:\n",
    "        print(f\"Fetching books for genre: {genre}\")\n",
    "        books = fetch_books_by_subject(genre, batch_size=100, max_books=200)\n",
    "        all_books.extend(books)\n",
    "        if len(all_books) >= 2000:\n",
    "            break\n",
    "\n",
    "    # Limit to a total of 1000 records\n",
    "    all_books = all_books[:1000]\n",
    "    \n",
    "    print(f\"Total books fetched: {len(all_books)}\")\n",
    "    insert_books(all_books)\n",
    "\n",
    "    # Verify insertion\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM books\")\n",
    "    count = cursor.fetchone()[0]\n",
    "    print(f\"Total books in the database: {count}\")\n",
    "\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Didn't run because of api limit reached\n",
    "\n",
    "'''from urllib.parse import quote_plus\n",
    "\n",
    "params = configr()\n",
    "conn = psy.connect(**params)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def extract_year(date_str):\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', date_str)\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    return None\n",
    "\n",
    "def fetch_books_from_google_books(query, max_books=100):\n",
    "    books_data = []\n",
    "    page = 0\n",
    "\n",
    "    while len(books_data) < max_books:\n",
    "        # Construct query URL\n",
    "        url = f\"https://www.googleapis.com/books/v1/volumes?q={quote_plus(query)}&startIndex={page * 10}&maxResults=10&key=<your key>\"\n",
    "        print(f\"Requesting data from URL: {url}\")\n",
    "\n",
    "        response = requests.get(url)\n",
    "        print(f\"Response status code: {response.status_code}\")\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(\"Error fetching data from the API\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        items = data.get('items', [])\n",
    "        if not items:\n",
    "            print(\"No more books to fetch from the API.\")\n",
    "            break\n",
    "\n",
    "        for item in items:\n",
    "            volume_info = item.get('volumeInfo', {})\n",
    "            title = volume_info.get(\"title\", \"\")[:255]  # Truncate to 255 characters\n",
    "            author = ', '.join(volume_info.get(\"authors\", []))[:255]  # Truncate to 255 characters\n",
    "            genre = ', '.join(volume_info.get(\"categories\", []))[:100]  # Assuming genre column has enough length\n",
    "            year_published_str = volume_info.get(\"publishedDate\", \"\")\n",
    "            year_published = extract_year(year_published_str) if year_published_str else None\n",
    "            description = volume_info.get('description', None)  # Use None if no description is available\n",
    "\n",
    "            # Only add books with a description\n",
    "            if description:\n",
    "                book = {\n",
    "                    \"title\": title,\n",
    "                    \"author\": author,\n",
    "                    \"genre\": genre,\n",
    "                    \"year_published\": year_published,\n",
    "                    \"summary\": description[:1000]  # Truncate to 1000 characters\n",
    "                }\n",
    "                books_data.append(book)\n",
    "\n",
    "            if len(books_data) >= max_books:\n",
    "                break\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    print(f\"Fetched {len(books_data)} books for query: {query}\")\n",
    "    return books_data\n",
    "\n",
    "def insert_books(books):\n",
    "    if not books:\n",
    "        print(\"No books to insert.\")\n",
    "        return\n",
    "\n",
    "    book_records = [\n",
    "        (\n",
    "            book['title'], \n",
    "            book['author'], \n",
    "            book['genre'], \n",
    "            book['year_published'], \n",
    "            book['summary']\n",
    "        ) for book in books\n",
    "    ]\n",
    "    \n",
    "    cursor.executemany(\"\"\"\n",
    "        INSERT INTO books (title, author, genre, year_published, summary)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\", book_records)\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"Inserted {len(book_records)} books into the database.\")\n",
    "\n",
    "def main():\n",
    "    queries = [\n",
    "        \"fiction\", \"mystery\", \"science\", \"history\", \"biography\", \"fantasy\", \n",
    "        \"romance\", \"non-fiction\", \"horror\", \"adventure\",\n",
    "        \"science-fiction\", \"thriller\", \"poetry\", \"philosophy\", \"travel\", \n",
    "        \"humor\",\"art\", \"religion\", \"spirituality\"\n",
    "    ]\n",
    "\n",
    "    all_books = []\n",
    "    for query in queries:\n",
    "        print(f\"Fetching books for query: {query}\")\n",
    "        books = fetch_books_from_google_books(query, max_books=100)\n",
    "        all_books.extend(books)\n",
    "        if len(all_books) >= 1000:\n",
    "            break\n",
    "\n",
    "        # Write records to database after processing each genre\n",
    "        insert_books(books)\n",
    "\n",
    "    # Limit to a total of 1000 records\n",
    "    all_books = all_books[:1000]\n",
    "    \n",
    "    print(f\"Total books fetched: {len(all_books)}\")\n",
    "\n",
    "    # Write remaining records to the database\n",
    "    if all_books:\n",
    "        insert_books(all_books)\n",
    "\n",
    "    # Verify insertion\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM books\")\n",
    "    count = cursor.fetchone()[0]\n",
    "    print(f\"Total books in the database: {count}\")\n",
    "\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching reviews for book ID 24277: Under the Greenwood Tree or, The Mellstock quire\n",
      "Found 7 reviews\n",
      "Fetching reviews for book ID 24083: Pride and Prejudice\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24278: Kidnapped\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24365: Cat Among the Pigeons\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 25011: Pictures from Italy\n",
      "Found 4 reviews\n",
      "Fetching reviews for book ID 24084: Alice's Adventures in Wonderland\n",
      "No reviews found\n",
      "Fetching reviews for book ID 24085: Adventures of Huckleberry Finn\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24086: Emma\n",
      "Found 6 reviews\n",
      "Fetching reviews for book ID 24087: Frankenstein or The Modern Prometheus\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24088: The Picture of Dorian Gray\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 15 reviews into the database.\n",
      "Fetching reviews for book ID 24089: Wuthering Heights\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24090: Sense and Sensibility\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24091: Treasure Island\n",
      "Error fetching reviews for book ID '24091': HTTPSConnectionPool(host='www.goodreads.com', port=443): Max retries exceeded with url: /book/show/24091 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000225B7F32A20>, 'Connection to www.goodreads.com timed out. (connect timeout=10)'))\n",
      "Retrying... (1/3)\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24092: Little Women\n",
      "Found 8 reviews\n",
      "Fetching reviews for book ID 24093: A Tale of Two Cities\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24094: A Christmas Carol\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24095: Gulliver's Travels\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 20 reviews into the database.\n",
      "Fetching reviews for book ID 24096: A Study in Scarlet\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24097: The Call of the Wild\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24098: Oliver Twist\n",
      "Found 19 reviews\n",
      "Fetching reviews for book ID 24099: Hamlet\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 2 reviews into the database.\n",
      "Fetching reviews for book ID 24100: Anne of Green Gables\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24101: The Hound of the Baskervilles\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24102: Don Quixote\n",
      "Found 12 reviews\n",
      "Fetching reviews for book ID 24103: Great Expectations\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24104: Persuasion\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24105: Through the Looking-Glass\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 21 reviews into the database.\n",
      "Fetching reviews for book ID 24106: The Great Gatsby\n",
      "Found 9 reviews\n",
      "Fetching reviews for book ID 24107: The Time Machine\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24108: The Adventures of Sherlock Holmes [12 stories]\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 25012: Samlede Vaerker\n",
      "Found 21 reviews\n",
      "Fetching reviews for book ID 24109: Moby Dick\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 9 reviews into the database.\n",
      "Fetching reviews for book ID 24110: Les Trois Mousquetaires\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24111: Mansfield Park\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24112: Ἰλιάς\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24113: Candide\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24114: Ὀδύσσεια\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 14 reviews into the database.\n",
      "Fetching reviews for book ID 24115: The Wonderful Wizard of Oz\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24116: The Mysterious Affair at Styles\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24117: Northanger Abbey\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24118: Ethan Frome\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 12 reviews into the database.\n",
      "Fetching reviews for book ID 24119: Romeo and Juliet\n",
      "Found 10 reviews\n",
      "Fetching reviews for book ID 24302: The After House\n",
      "Found 10 reviews\n",
      "Fetching reviews for book ID 24120: The Sign of Four\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24121: Macbeth\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24122: Die Verwandlung\n",
      "Found 12 reviews\n",
      "Fetching reviews for book ID 24123: Anna Karenina\n",
      "Error fetching reviews for book ID '24123': HTTPSConnectionPool(host='www.goodreads.com', port=443): Read timed out.\n",
      "Retrying... (1/3)\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 2 reviews into the database.\n",
      "Fetching reviews for book ID 24124: The Adventures of Tom Sawyer\n",
      "Found 22 reviews\n",
      "Fetching reviews for book ID 24125: The Secret Garden\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24126: The Last of the Mohicans\n",
      "Found 33 reviews\n",
      "Processed 50 books.\n",
      "Fetching reviews for book ID 24127: The Prince\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 3 reviews into the database.\n",
      "Fetching reviews for book ID 24128: Hard Times\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24129: The Scarlet Letter\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24130: Tempest\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24131: πολιτεία\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 16 reviews into the database.\n",
      "Fetching reviews for book ID 24132: A Connecticut Yankee in King Arthur's Court\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24133: Jane Eyre\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24134: Anne's House of Dreams\n",
      "Found 4 reviews\n",
      "Fetching reviews for book ID 24135: The Merchant of Venice\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24136: Madame Bovary\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 16 reviews into the database.\n",
      "Fetching reviews for book ID 24137: The Valley of Fear\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24138: The Prince and the Pauper\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24139: Tess of the d'Urbervilles\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24140: The Lost World\n",
      "Found 4 reviews\n",
      "Fetching reviews for book ID 24141: The Secret Adversary\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24142: Le Comte de Monte Cristo\n",
      "No reviews found\n",
      "Fetching reviews for book ID 24143: Dracula\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24144: Three Men in a Boat (to say nothing of the dog)\n",
      "No reviews found\n",
      "Fetching reviews for book ID 24145: Anne of Avonlea\n",
      "Found 8 reviews\n",
      "Fetching reviews for book ID 24146: The Canterbury Tales\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24147: The Thirty-Nine Steps\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24148: Leaves of Grass\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24149: Divina Commedia\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 20 reviews into the database.\n",
      "Fetching reviews for book ID 24150: Othello\n",
      "Found 11 reviews\n",
      "Fetching reviews for book ID 24151: Julius Caesar\n",
      "Found 23 reviews\n",
      "Fetching reviews for book ID 24152: King Lear\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24153: Decamerone\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24154: The House of Mirth\n",
      "Error fetching reviews for book ID '24154': HTTPSConnectionPool(host='www.goodreads.com', port=443): Read timed out. (read timeout=10)\n",
      "Retrying... (1/3)\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 5 reviews into the database.\n",
      "Fetching reviews for book ID 24155: Dubliners\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24156: The Pilgrim's Progress\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24157: David Copperfield\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24158: Uncle Tom's Cabin\n",
      "Found 11 reviews\n",
      "Fetching reviews for book ID 24159: War and Peace\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 22 reviews into the database.\n",
      "Fetching reviews for book ID 24160: The Red Badge of Courage\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24344: Appointment with Death\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24161: The Moonstone\n",
      "Found 9 reviews\n",
      "Fetching reviews for book ID 24162: Narrative of the life of Frederick Douglass, an American slave\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24163: The Prisoner of Zenda\n",
      "Found 4 reviews\n",
      "Fetching reviews for book ID 24164: Rainbow Valley\n",
      "Found 3 reviews\n",
      "Fetching reviews for book ID 24165: Five Children and It\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 20 reviews into the database.\n",
      "Fetching reviews for book ID 24166: The Scarlet Letter\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24167: Lady Susan\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24168: Jo's Boys\n",
      "Found 33 reviews\n",
      "Fetching reviews for book ID 24169: Eight cousins\n",
      "Found 33 reviews\n",
      "Inserted 100 reviews into the database.\n",
      "Inserted 12 reviews into the database.\n",
      "Fetching reviews for book ID 24170: The Scarlet Pimpernel\n",
      "Found 13 reviews\n",
      "Fetching reviews for book ID 24181: Alice's Adventures in Wonderland / Through the Looking Glass\n",
      "No reviews found\n",
      "Fetching reviews for book ID 24182: The Old Curiosity Shop\n",
      "Found 10 reviews\n",
      "Fetching reviews for book ID 24366: The Clocks\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 153\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Execute the main function\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# Close the connection\u001b[39;00m\n\u001b[0;32m    156\u001b[0m cursor\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[1;32mIn[45], line 133\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, (book_id, book_title) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(books, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching reviews for book ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbook_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbook_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m     reviews \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_reviews_and_rating\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbook_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbook_title\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     all_reviews\u001b[38;5;241m.\u001b[39mextend(reviews)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# Print status for every 50th book\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[45], line 38\u001b[0m, in \u001b[0;36mfetch_reviews_and_rating\u001b[1;34m(book_id, book_title, max_retries)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retries \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m         response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     41\u001b[0m         soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1095\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:615\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m    617\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fetch reviews and insert records into Review Table\n",
    "\n",
    "params = configr()\n",
    "conn = psy.connect(**params)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SET client_encoding = 'UTF8';\")\n",
    "conn.commit()\n",
    "\n",
    "# Function to clean and encode text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        try:\n",
    "            return text.encode('utf-8', 'ignore').decode('utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            return text\n",
    "    return text\n",
    "\n",
    "# Function to fetch book IDs and titles from the `books` table\n",
    "def fetch_book_ids_and_titles():\n",
    "    cursor.execute(\"SELECT id, title FROM books\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "# Function to fetch reviews and rating from Goodreads for a specific book\n",
    "def fetch_reviews_and_rating(book_id, book_title, max_retries=3):\n",
    "    reviews_data = []\n",
    "    \n",
    "    # Use direct book page URL\n",
    "    url = f\"https://www.goodreads.com/book/show/{book_id}\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Extract ratings\n",
    "            rating_elements = soup.find_all('span', class_='RatingStars')\n",
    "            ratings = [elem.get('aria-label', '').split(' ')[1] for elem in rating_elements]\n",
    "            \n",
    "            # Find all review sections\n",
    "            review_elements = soup.find_all('span', class_='Formatted')\n",
    "            if review_elements:\n",
    "                print(f\"Found {len(review_elements)} reviews\")\n",
    "            else:\n",
    "                print(\"No reviews found\")\n",
    "\n",
    "            for i, review in enumerate(review_elements, 1):\n",
    "                review_text = clean_text(review.get_text(strip=True))\n",
    "                \n",
    "                # Use the corresponding rating for each review\n",
    "                rating = ratings[i-1] if i-1 < len(ratings) else None\n",
    "                \n",
    "                # Validate rating value\n",
    "                if rating is not None:\n",
    "                    try:\n",
    "                        rating = float(rating)\n",
    "                        if rating < 1 or rating > 5:  \n",
    "                            rating = None\n",
    "                    except ValueError:\n",
    "                        rating = None\n",
    "                else:\n",
    "                    rating = None\n",
    "                \n",
    "                if review_text and rating is not None:\n",
    "                    reviews_data.append({\n",
    "                        \"book_id\": book_id,\n",
    "                        \"user_id\": 1,\n",
    "                        \"review_text\": review_text,\n",
    "                        \"rating\": rating\n",
    "                    })\n",
    "                    if len(reviews_data) % 50 == 0:\n",
    "                        print(f\"Review {len(reviews_data)}: {review_text}\\nRating: {rating}\\n\")\n",
    "                    \n",
    "            break  # Exit loop if successful\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching reviews for book ID '{book_id}': {e}\")\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                print(f\"Retrying... ({retries}/{max_retries})\")\n",
    "                time.sleep(2)  # Wait 2 seconds before retrying\n",
    "            else:\n",
    "                print(f\"Failed to fetch reviews for book ID '{book_id}' after {max_retries} attempts.\")\n",
    "    \n",
    "    return reviews_data\n",
    "\n",
    "\n",
    "# Function to insert reviews into the `review` table\n",
    "def insert_reviews(reviews):\n",
    "    try:\n",
    "        if not reviews:\n",
    "            print(\"No reviews to insert.\")\n",
    "            return\n",
    "\n",
    "        batch_size = 100\n",
    "        for i in range(0, len(reviews), batch_size):\n",
    "            batch = reviews[i:i + batch_size]\n",
    "            for review in batch:\n",
    "                # Convert rating to float\n",
    "                try:\n",
    "                    rating = float(review['rating'])\n",
    "                except ValueError:\n",
    "                    print(f\"Invalid rating value: {review['rating']}\")\n",
    "                    continue\n",
    "\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO review (book_id, user_id, review_text, rating)\n",
    "                    VALUES (%s, %s, %s, %s)\n",
    "                    \"\"\", (review['book_id'], review['user_id'], review['review_text'], rating)\n",
    "                )\n",
    "            conn.commit()\n",
    "            print(f\"Inserted {len(batch)} reviews into the database.\")\n",
    "    except psy.DatabaseError as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        conn.rollback()  # Rollback in case of an error\n",
    "\n",
    "# Main function to process all books\n",
    "def main():\n",
    "    books = fetch_book_ids_and_titles()\n",
    "    if not books:\n",
    "        print(\"No books found in the database.\")\n",
    "        return\n",
    "\n",
    "    all_reviews = []\n",
    "    for index, (book_id, book_title) in enumerate(books, 1):\n",
    "        print(f\"Fetching reviews for book ID {book_id}: {book_title}\")\n",
    "        reviews = fetch_reviews_and_rating(book_id, book_title)\n",
    "        all_reviews.extend(reviews)\n",
    "\n",
    "        # Print status for every 50th book\n",
    "        if index % 50 == 0:\n",
    "            print(f\"Processed {index} books.\")\n",
    "\n",
    "        # Insert reviews into the database every 100 records\n",
    "        if len(all_reviews) >= 100:\n",
    "            insert_reviews(all_reviews)\n",
    "            all_reviews = []  # Reset reviews list after insertion\n",
    "\n",
    "    # Insert any remaining reviews\n",
    "    if all_reviews:\n",
    "        insert_reviews(all_reviews)\n",
    "\n",
    "    print(\"Processing completed for all books.\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching reviews for book ID 24277: Under the Greenwood Tree or, The Mellstock quire\n",
      "Rating: 4.18\n",
      "Rating: 4.18\n",
      "Found 7 reviews\n",
      "Review 1: NEW EDITION 'Magic that takes you out, far out, of this time and this world.' George Bernard Shaw, after a visit to Skellig This is the story of two of the world's most stunning and unspoilt islands, Skellig Michael and Small Skellig, which lie off the coast of Kerry. Lavelle explores the extraordinary, isolated Early Christian monastic settlement with its stone 'beehive' huts. He describes the abundant bird life, including the huge colony of gannets, and tells of the history, the legends, geology, plant life, the lighthouse, the seals and the underwater world. A comprehensive and accessible book on a unique and fascinating place.\n",
      "\n",
      "Review 4: This fairly short book provides a nice overview of the Skelligs by an author who clearly has a deep interest and knowledge of all aspects of these unique islands. The topography, geology and flora and fauna of the Skelligs and the surrounding seas are dealt with in some detail but the historical sections of the book seem to be somewhat less detailed. Although this may simply be due to a scarcity of historical data, the stories and legends that are mentioned provide a fascinating, if limited, perspective on life in the monastery and the lighthouses on Skellig Michael. Overall a very pleasant read for anyone interested in the Skelligs.\n",
      "\n",
      "Review 5: Was looking for a bit more detail in both the section about the monastic times as well as the geology. Gives a good enough overview of the island history and birds.\n",
      "\n",
      "Review 6: A good short history and natural history of the Skelligs, Skellig Michael and Little Skellig, two small rocky islands of the western coast of Ireland. Only reachable by boat about 5 months of the year and then only on good days, Skellig Michael was home to a monastic community who lived in stone beehive huts then later to lighthouse keepers. Both are home to thousands of sea birds. Des Lavelle has visited, sailed and dived by the Skelligs all his life and an ancestor was a lighthouse keeper. My husband and I have arranged for him to take us to Skellig Michael on our imminent trip to Ireland.\n",
      "\n",
      "Review 7: Dated, but a very clear description of the Skellig and its history, flora, fauna, etc, providing a good overview of the island.\n",
      "\n",
      "Fetched reviews for 'Under the Greenwood Tree or, The Mellstock quire': [{'book_id': 24277, 'user_id': 1, 'review_text': \"NEW EDITION 'Magic that takes you out, far out, of this time and this world.' George Bernard Shaw, after a visit to Skellig This is the story of two of the world's most stunning and unspoilt islands, Skellig Michael and Small Skellig, which lie off the coast of Kerry. Lavelle explores the extraordinary, isolated Early Christian monastic settlement with its stone 'beehive' huts. He describes the abundant bird life, including the huge colony of gannets, and tells of the history, the legends, geology, plant life, the lighthouse, the seals and the underwater world. A comprehensive and accessible book on a unique and fascinating place.\", 'rating': '4.18'}, {'book_id': 24277, 'user_id': 1, 'review_text': 'This fairly short book provides a nice overview of the Skelligs by an author who clearly has a deep interest and knowledge of all aspects of these unique islands. The topography, geology and flora and fauna of the Skelligs and the surrounding seas are dealt with in some detail but the historical sections of the book seem to be somewhat less detailed. Although this may simply be due to a scarcity of historical data, the stories and legends that are mentioned provide a fascinating, if limited, perspective on life in the monastery and the lighthouses on Skellig Michael. Overall a very pleasant read for anyone interested in the Skelligs.', 'rating': '4.18'}, {'book_id': 24277, 'user_id': 1, 'review_text': 'Was looking for a bit more detail in both the section about the monastic times as well as the geology. Gives a good enough overview of the island history and birds.', 'rating': '4.18'}, {'book_id': 24277, 'user_id': 1, 'review_text': 'A good short history and natural history of the Skelligs, Skellig Michael and Little Skellig, two small rocky islands of the western coast of Ireland. Only reachable by boat about 5 months of the year and then only on good days, Skellig Michael was home to a monastic community who lived in stone beehive huts then later to lighthouse keepers. Both are home to thousands of sea birds. Des Lavelle has visited, sailed and dived by the Skelligs all his life and an ancestor was a lighthouse keeper. My husband and I have arranged for him to take us to Skellig Michael on our imminent trip to Ireland.', 'rating': '4.18'}, {'book_id': 24277, 'user_id': 1, 'review_text': 'Dated, but a very clear description of the Skellig and its history, flora, fauna, etc, providing a good overview of the island.', 'rating': '4.18'}]\n",
      "Inserted 5 reviews into the database.\n",
      "Processing completed for the first book.\n"
     ]
    }
   ],
   "source": [
    "# params = configr()\n",
    "# conn = psy.connect(**params)\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# cursor.execute(\"SET client_encoding = 'UTF8';\")\n",
    "# conn.commit()\n",
    "\n",
    "# # Function to clean and encode text\n",
    "# def clean_text(text):\n",
    "#     if isinstance(text, str):\n",
    "#         try:\n",
    "#             return text.encode('utf-8', 'ignore').decode('utf-8')\n",
    "#         except UnicodeDecodeError:\n",
    "#             return text\n",
    "#     return text\n",
    "\n",
    "# # Function to fetch book IDs and titles from the `books` table\n",
    "# def fetch_book_ids_and_titles(limit=1):\n",
    "#     cursor.execute(\"SELECT id, title FROM books LIMIT %s\", (limit,))\n",
    "#     return cursor.fetchall()\n",
    "\n",
    "# # Function to fetch reviews and rating from Goodreads for a specific book\n",
    "# def fetch_reviews_and_rating(book_id, book_title, max_retries=3):\n",
    "#     reviews_data = []\n",
    "    \n",
    "#     # Use direct book page URL\n",
    "#     url = f\"https://www.goodreads.com/book/show/{book_id}\"\n",
    "#     headers = {\n",
    "#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "#     }\n",
    "\n",
    "#     retries = 0\n",
    "#     while retries < max_retries:\n",
    "#         try:\n",
    "#             response = requests.get(url, headers=headers, timeout=10)\n",
    "#             response.raise_for_status()\n",
    "            \n",
    "#             soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "#             # Print raw HTML for debugging\n",
    "#             # Uncomment this line to debug the HTML structure\n",
    "#             # print(soup.prettify())\n",
    "\n",
    "#             # Find the rating\n",
    "#             rating_element = soup.find('div', class_='RatingStatistics__column')\n",
    "#             if rating_element:\n",
    "#                 aria_label = rating_element.get('aria-label', '')\n",
    "#                 if aria_label:\n",
    "#                     rating = aria_label.split(' ')[-2]  # Extract rating value\n",
    "#                     print(f\"Rating: {rating}\")\n",
    "#                 else:\n",
    "#                     rating = 'Rating not found'\n",
    "#             else:\n",
    "#                 rating = 'Rating section not found'\n",
    "#             print(f\"Rating: {rating}\")\n",
    "\n",
    "#             # Find all review sections\n",
    "#             review_elements = soup.find_all('span', class_='Formatted')\n",
    "#             if review_elements:\n",
    "#                 print(f\"Found {len(review_elements)} reviews\")\n",
    "#             else:\n",
    "#                 print(\"No reviews found\")\n",
    "\n",
    "#             for i, review in enumerate(review_elements, 1):\n",
    "#                 review_text = clean_text(review.get_text(strip=True))\n",
    "                \n",
    "#                 if review_text:\n",
    "#                     reviews_data.append({\n",
    "#                         \"book_id\": book_id,\n",
    "#                         \"user_id\": 1,  # Assuming a fixed user ID for this example\n",
    "#                         \"review_text\": review_text,\n",
    "#                         \"rating\": rating\n",
    "#                     })\n",
    "#                     print(f\"Review {i}: {review_text}\\n\")\n",
    "                    \n",
    "#             print(f\"Fetched reviews for '{book_title}': {reviews_data}\")  # Print fetched reviews\n",
    "#             break  # Exit loop if successful\n",
    "#         except requests.exceptions.RequestException as e:\n",
    "#             print(f\"Error fetching reviews for book ID '{book_id}': {e}\")\n",
    "#             retries += 1\n",
    "#             if retries < max_retries:\n",
    "#                 print(f\"Retrying... ({retries}/{max_retries})\")\n",
    "#                 time.sleep(2)  # Wait 2 seconds before retrying\n",
    "#             else:\n",
    "#                 print(f\"Failed to fetch reviews for book ID '{book_id}' after {max_retries} attempts.\")\n",
    "    \n",
    "#     return reviews_data\n",
    "\n",
    "# # Function to insert reviews into the `reviews` table\n",
    "# # Function to insert reviews into the `reviews` table\n",
    "# def insert_reviews(reviews):\n",
    "#     try:\n",
    "#         if not reviews:\n",
    "#             print(\"No reviews to insert.\")\n",
    "#             return\n",
    "\n",
    "#         for review in reviews:\n",
    "#             # Convert rating to float\n",
    "#             try:\n",
    "#                 rating = float(review['rating'])\n",
    "#             except ValueError:\n",
    "#                 print(f\"Invalid rating value: {review['rating']}\")\n",
    "#                 continue\n",
    "\n",
    "#             cursor.execute(\"\"\"\n",
    "#                 INSERT INTO reviews (book_id, user_id, review_text, rating)\n",
    "#                 VALUES (%s, %s, %s, %s)\n",
    "#                 \"\"\", (review['book_id'], review['user_id'], review['review_text'], rating)\n",
    "#             )\n",
    "#         conn.commit()\n",
    "#         print(f\"Inserted {len(reviews)} reviews into the database.\")\n",
    "#     except psy.DatabaseError as e:\n",
    "#         print(f\"Database error: {e}\")\n",
    "#         conn.rollback()  # Rollback in case of an error\n",
    "\n",
    "\n",
    "# # Main function to process the first book only\n",
    "# def main():\n",
    "#     # Fetch only the first book\n",
    "#     books = fetch_book_ids_and_titles(limit=1)\n",
    "#     if not books:\n",
    "#         print(\"No books found in the database.\")\n",
    "#         return\n",
    "\n",
    "#     book_id, book_title = books[0]\n",
    "#     print(f\"Fetching reviews for book ID {book_id}: {book_title}\")\n",
    "#     reviews = fetch_reviews_and_rating(book_id, book_title)\n",
    "#     insert_reviews(reviews)\n",
    "\n",
    "#     print(\"Processing completed for the first book.\")\n",
    "\n",
    "# # Execute the main function\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "# # Close the connection\n",
    "# cursor.close()\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
